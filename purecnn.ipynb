{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "purecnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "f6-nZpyLFWRR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "ROOT='/content/drive/MyDrive/Colab Notebooks/CNN'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(ROOT)\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ATzPgrMIFopE",
        "outputId": "7edf0aa3-41f6-424a-b5b1-dba5c98a5779"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/CNN'"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "BHdOyv1_F9jG"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6rcJ-rb4GT8r",
        "outputId": "b7950ec7-773e-4e7f-f872-6d4a0e639477"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.8.0'"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "EP7rtWWO5U3e"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "# use Keras to import pre-shuffled MNIST database\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "3di_UMZ156AR"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32')/255\n",
        "X_test = X_test.astype('float32')/255 "
      ],
      "metadata": {
        "id": "_ZwAfkxf6piW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5OCoudi60nm",
        "outputId": "612d0472-b0cf-4bc7-833a-13c0cd8a9512"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (60000, 28, 28)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "num_classes = 10 \n",
        "# print first ten (integer-valued) training labels\n",
        "print('Integer-valued labels:')\n",
        "print(y_train[:10])\n",
        "\n",
        "# one-hot encode the labels\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# print first ten (one-hot) training labels\n",
        "print('One-hot labels:')\n",
        "print(y_train[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzQuH3Yp66SO",
        "outputId": "c209e7f1-06bf-465f-ff70-639aafa8c4fa"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Integer-valued labels:\n",
            "[5 0 4 1 9 2 1 3 1 4]\n",
            "One-hot labels:\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input image dimensions 28x28 pixel images. \n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "print('input_shape: ', input_shape)\n",
        "print('x_train shape:', X_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFl3POzu8A4r",
        "outputId": "c6080887-365b-41e3-a1f9-4d5500c5d51e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_shape:  (28, 28, 1)\n",
            "x_train shape: (60000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D,Activation\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(10,kernel_size=(3,3,),padding='same',activation='relu',input_shape=input_shape))#26\n",
        "model.add(Conv2D(16, (3, 3),padding='same', activation='relu'))#24\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(16, kernel_size=(3,3),padding='same', activation='relu'))#12\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Conv2D(16,kernel_size=(3,3),padding='same', activation='relu'))#6\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(10,kernel_size=(3,3,)))#1\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c4nCzAkk8tpi"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ATTkyYZHCkg",
        "outputId": "c57bfa1f-1297-4e62-a9d5-b3095d2e7e13"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_54 (Conv2D)          (None, 28, 28, 10)        100       \n",
            "                                                                 \n",
            " conv2d_55 (Conv2D)          (None, 28, 28, 16)        1456      \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 14, 14, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_56 (Conv2D)          (None, 14, 14, 16)        2320      \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 7, 7, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 7, 7, 16)          0         \n",
            "                                                                 \n",
            " conv2d_57 (Conv2D)          (None, 7, 7, 16)          2320      \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (None, 3, 3, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_58 (Conv2D)          (None, 1, 1, 10)          1450      \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 10)                0         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,646\n",
            "Trainable params: 7,646\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We are importing the Adam Optimizer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# We are importing the learningratescheduler callback\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "#Creating the \"scheduler\" function with two arguments i.e learningrate and epoch\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "#\tLearningRate = LearningRate * 1/(1 + decay * epoch) here decay is 0.319 and epoch is 10.\n",
        "\n",
        "# here we are compiling our model and using 'categorical_crossentropy' as our loss function and adam as our optimizer with learning rate =0.003 and metrics is accuracy\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "# Here we are traing our model using the data and using batch size of 128,number of epochs are 20 and using verbose=1 for printing out all the results.\n",
        "# In the callbacks parameter we are using the LearningRateScheduler which takes two arguments scheduler function which we built earlier to reduce the learning rate in each decay and verbose =1\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIZ7nRUlH5Vs",
        "outputId": "eead881b-34d7-4cc5-9448-8ca59a3bb27e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.003.\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 16s 13ms/step - loss: 0.2888 - accuracy: 0.9080 - val_loss: 0.0778 - val_accuracy: 0.9749 - lr: 0.0030\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0820 - accuracy: 0.9745 - val_loss: 0.0507 - val_accuracy: 0.9828 - lr: 0.0023\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0599 - accuracy: 0.9814 - val_loss: 0.0467 - val_accuracy: 0.9847 - lr: 0.0018\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0499 - accuracy: 0.9840 - val_loss: 0.0346 - val_accuracy: 0.9878 - lr: 0.0015\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0424 - accuracy: 0.9864 - val_loss: 0.0350 - val_accuracy: 0.9877 - lr: 0.0013\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0379 - accuracy: 0.9883 - val_loss: 0.0291 - val_accuracy: 0.9895 - lr: 0.0012\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0350 - accuracy: 0.9891 - val_loss: 0.0303 - val_accuracy: 0.9883 - lr: 0.0010\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0326 - accuracy: 0.9895 - val_loss: 0.0302 - val_accuracy: 0.9905 - lr: 9.2793e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.0280 - val_accuracy: 0.9904 - lr: 8.4459e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0295 - accuracy: 0.9904 - val_loss: 0.0265 - val_accuracy: 0.9900 - lr: 7.7499e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.0286 - val_accuracy: 0.9895 - lr: 7.1599e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.0264 - val_accuracy: 0.9916 - lr: 6.6534e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.0257 - val_accuracy: 0.9909 - lr: 6.2138e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.0256 - val_accuracy: 0.9911 - lr: 5.8286e-04\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0226 - accuracy: 0.9928 - val_loss: 0.0259 - val_accuracy: 0.9920 - lr: 5.4885e-04\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.0241 - val_accuracy: 0.9912 - lr: 5.1858e-04\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0246 - val_accuracy: 0.9913 - lr: 4.9148e-04\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.0241 - val_accuracy: 0.9920 - lr: 4.6707e-04\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.0224 - val_accuracy: 0.9918 - lr: 4.4497e-04\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.0231 - val_accuracy: 0.9920 - lr: 4.2487e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2141bd0090>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}